{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules & Read in Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/kevinmacmat/Documents/flatiron/module_projects/capstone/csv/sqr_no_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Base Number (DBN) & Features List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of all DBN's to pass into end of https://insideschools.org/school/ url as well as lists for all relevant SQR features to add to the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbn_list = list(df.dbn)\n",
    "grade_level_list = list(df.school_type)\n",
    "enrollment_list = list(df.enrollment)\n",
    "fam_comm_ties_list = list(df.fam_comm_ties_rating)\n",
    "pct_ell_list = list(df.pct_ell)\n",
    "pct_disabilities_list = list(df.pct_disabilities)\n",
    "pct_self_contained_list = list(df.pct_self_contained)\n",
    "economic_need_index_list = list(df.economic_need_index)\n",
    "pct_temp_housing_list = list(df.pct_temp_housing)\n",
    "pct_hra_eligible_list = list(df.pct_hra_eligible)\n",
    "pct_asian_list = list(df.pct_asian)\n",
    "pct_black_list = list(df.pct_black)\n",
    "pct_hispanic_list = list(df.pct_hispanic)\n",
    "pct_white_list = list(df.pct_white)\n",
    "pct_chronic_absent_list = list(df.pct_chronic_absent)\n",
    "borough_list = list(df.borough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust dbn_list range in order to scrape and save in batches. Ran into issues when trying to scrape too much at one time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_range_start = 0\n",
    "scrape_range_stop = 3\n",
    "\n",
    "dbn_list = dbn_list[scrape_range_start:scrape_range_stop]\n",
    "grade_level_list = grade_level_list[scrape_range_start:scrape_range_stop]\n",
    "enrollment_list = enrollment_list[scrape_range_start:scrape_range_stop]\n",
    "fam_comm_ties_list = fam_comm_ties_list[scrape_range_start:scrape_range_stop]\n",
    "pct_ell_list = pct_ell_list[scrape_range_start:scrape_range_stop]\n",
    "pct_disabilities_list = pct_disabilities_list[scrape_range_start:scrape_range_stop]\n",
    "pct_self_contained_list = pct_self_contained_list[scrape_range_start:scrape_range_stop]\n",
    "ecomonic_need_index_list = economic_need_index_list[scrape_range_start:scrape_range_stop]\n",
    "pct_temp_housing_list = pct_temp_housing_list[scrape_range_start:scrape_range_stop]\n",
    "pct_hra_eligible_list = pct_hra_eligible_list[scrape_range_start:scrape_range_stop]\n",
    "pct_asian_list = pct_asian_list[scrape_range_start:scrape_range_stop]\n",
    "pct_black_list = pct_black_list[scrape_range_start:scrape_range_stop]\n",
    "pct_hispanic_list = pct_hispanic_list[scrape_range_start:scrape_range_stop]\n",
    "pct_white_list = pct_white_list[scrape_range_start:scrape_range_stop]\n",
    "pct_chronic_absent_list = pct_chronic_absent_list[scrape_range_start:scrape_range_stop]\n",
    "borough_list = borough_list[scrape_range_start:scrape_range_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Selenium's headless mode option so browser does not continually open with every school's website. Must set a path to Selenium's downloaded chromedriver in order to function properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ChromeOptions\n",
    "options = webdriver.ChromeOptions()\n",
    "# Run headless mode \n",
    "options.add_argument(\"headless\")\n",
    "# Instatiate chrome driver and pass in the file path to chromedriver\n",
    "driver = webdriver.Chrome('/Users/kevinmacmat/Documents/flatiron/module_projects/capstone/chromedriver', options=options) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get comments for past 6 years and output them to output_list. The 6 year cutoff was determined due to the SQR's availability for those years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate containers for comment features\n",
    "raw_message = []\n",
    "depth = []\n",
    "dislikes = []\n",
    "likes = []\n",
    "name = []\n",
    "dbns = []\n",
    "post_date = []\n",
    "borough = []\n",
    "grade_level = []\n",
    "enrollment = []\n",
    "fam_comm_ties = []\n",
    "pct_ell = []\n",
    "pct_disabilities = []\n",
    "pct_self_contained = []\n",
    "economic_need_index = []\n",
    "pct_temp_housing = []\n",
    "pct_hra_eligible = []\n",
    "pct_asian = []\n",
    "pct_black = []\n",
    "pct_hispanic = []\n",
    "pct_white = []\n",
    "pct_chronic_absent = []\n",
    "\n",
    "for index, dbn in enumerate(dbn_list):\n",
    "    # Get website \n",
    "    driver.get('https://insideschools.org/school/' + dbn)\n",
    "    # Switch to iframe containing script tag\n",
    "    driver.switch_to.frame(1)\n",
    "    # Grab the text\n",
    "    text = driver.page_source\n",
    "    # Switch out of iframe\n",
    "    driver.switch_to.default_content()\n",
    "    # Parse and process the source with BeautifulSoup module by creating an BS object\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    # Access the soup and find the script element's id\n",
    "    thread = soup.find(\"script\", {\"id\": \"disqus-threadData\"})\n",
    "    # Turn the bs4 tag into a string, remove the script tag, and access the json\n",
    "    site_json = json.loads(str(thread)[48:-9])\n",
    "    # Navigate and loop json, filtering comments by date, to append comments to comments_list\n",
    "    for comment in site_json['response']['posts']:\n",
    "        if '2014' or '2015' or '2016' or '2017' or '2018' or '2019' or '2020' in comment['createdAt']:\n",
    "            raw_message.append(comment['raw_message'])\n",
    "            depth.append(comment['depth'])\n",
    "            dislikes.append(comment['dislikes'])\n",
    "            likes.append(comment['likes'])\n",
    "            name.append(comment['author']['name'])\n",
    "            post_date.append(comment['createdAt'])\n",
    "            dbns.append(dbn)\n",
    "            borough.append(borough_list[index])\n",
    "            grade_level.append(grade_level_list[index])\n",
    "            enrollment.append(enrollment_list[index])\n",
    "            fam_comm_ties.append(fam_comm_ties_list[index])\n",
    "            pct_ell.append(pct_ell_list[index])\n",
    "            pct_disabilities.append(pct_disabilities_list[index])\n",
    "            pct_self_contained.append(pct_self_contained_list[index])\n",
    "            economic_need_index.append(economic_need_index_list[index])\n",
    "            pct_temp_housing.append(pct_temp_housing_list[index])\n",
    "            pct_hra_eligible.append(pct_hra_eligible_list[index])\n",
    "            pct_asian.append(pct_asian_list[index])\n",
    "            pct_black.append(pct_black_list[index])\n",
    "            pct_hispanic.append(pct_hispanic_list[index])\n",
    "            pct_white.append(pct_white_list[index])\n",
    "            pct_chronic_absent.append(pct_chronic_absent_list[index])\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pct_disabilites' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-929b9d09ba90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mfam_comm_ties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfam_comm_ties_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mpct_ell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct_ell_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mpct_disabilites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct_disabilities_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mpct_self_contained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct_self_contained_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0meconomic_need_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meconomic_need_index_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pct_disabilites' is not defined"
     ]
    }
   ],
   "source": [
    "# # Instantiate containers for comment features\n",
    "# raw_message = []\n",
    "# depth = []\n",
    "# dislikes = []\n",
    "# likes = []\n",
    "# name = []\n",
    "# dbns = []\n",
    "# post_date = []\n",
    "# borough = []\n",
    "# grade_level = []\n",
    "# enrollment = []\n",
    "# fam_comm_ties = []\n",
    "# pct_ell = []\n",
    "# pct_disabilities = []\n",
    "# pct_self_contained = []\n",
    "# economic_need_index = []\n",
    "# pct_temp_housing = []\n",
    "# pct_hra_eligible = []\n",
    "# pct_asian = []\n",
    "# pct_black = []\n",
    "# pct_hispanic = []\n",
    "# pct_white = []\n",
    "# pct_chronic_absent = []\n",
    "\n",
    "# for index, dbn in enumerate(dbn_list):\n",
    "#     # Get website \n",
    "#     driver.get('https://insideschools.org/school/' + dbn)\n",
    "#     # Switch to iframe containing script tag\n",
    "#     driver.switch_to.frame(1)\n",
    "#     # Grab the text\n",
    "#     text = driver.page_source\n",
    "#     # Switch out of iframe\n",
    "#     driver.switch_to.default_content()\n",
    "#     # Parse and process the source with BeautifulSoup module by creating an BS object\n",
    "#     soup = BeautifulSoup(text, 'lxml')\n",
    "#     # Access the soup and find the script element's id\n",
    "#     thread = soup.find(\"script\", {\"id\": \"disqus-threadData\"})\n",
    "#     # Turn the bs4 tag into a string, remove the script tag, and access the json\n",
    "#     site_json = json.loads(str(thread)[48:-9])\n",
    "#     # Navigate and loop json, filtering comments by date, to append comments to comments_list\n",
    "#     for comment in site_json['response']['posts']:\n",
    "#         if '2014' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#             borough.append(borough_list[index])\n",
    "#             grade_level.append(grade_level_list[index])\n",
    "#             enrollment.append(enrollment_list[index])\n",
    "#             fam_comm_ties.append(fam_comm_ties_list[index])\n",
    "#             pct_ell.append(pct_ell_list[index])\n",
    "#             pct_disabilities.append(pct_disabilities_list[index])\n",
    "#             pct_self_contained.append(pct_self_contained_list[index])\n",
    "#             economic_need_index.append(economic_need_index_list[index])\n",
    "#             pct_temp_housing.append(pct_temp_housing_list[index])\n",
    "#             pct_hra_eligible.append(pct_hra_eligible_list[index])\n",
    "#             pct_asian.append(pct_asian_list[index])\n",
    "#             pct_black.append(pct_black_list[index])\n",
    "#             pct_hispanic.append(pct_hispanic_list[index])\n",
    "#             pct_white.append(pct_white_list[index])\n",
    "#             pct_chronic_absent.append(pct_chronic_absent_list[index])\n",
    "#         elif '2015' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#             borough.append(borough_list[index])\n",
    "#             grade_level.append(grade_level_list[index])\n",
    "#             enrollment.append(enrollment_list[index])\n",
    "#             fam_comm_ties.append(fam_comm_ties_list[index])\n",
    "#             pct_ell.append(pct_ell_list[index])\n",
    "#             pct_disabilites.append(pct_disabilities_list[index])\n",
    "#             pct_self_contained.append(pct_self_contained_list[index])\n",
    "#             economic_need_index.append(economic_need_index_list[index])\n",
    "#             pct_temp_housing.append(pct_temp_housing_list[index])\n",
    "#             pct_hra_eligible.append(pct_hra_eligible_list[index])\n",
    "#             pct_asian.append(pct_asian_list[index])\n",
    "#             pct_black.append(pct_black_list[index])\n",
    "#             pct_hispanic.append(pct_hispanic_list[index])\n",
    "#             pct_white.append(pct_white_list[index])\n",
    "#             pct_chronic_absent.append(pct_chronic_absent_list[index])\n",
    "#         elif '2016' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#             borough.append(borough_list[index])\n",
    "#             grade_level.append(grade_level_list[index])\n",
    "#             enrollment.append(enrollment_list[index])\n",
    "#             fam_comm_ties.append(fam_comm_ties_list[index])\n",
    "#             pct_ell.append(pct_ell_list[index])\n",
    "#             pct_disabilites.append(pct_disabilities_list[index])\n",
    "#             pct_self_contained.append(pct_self_contained_list[index])\n",
    "#             economic_need_index.append(economic_need_index_list[index])\n",
    "#             pct_temp_housing.append(pct_temp_housing_list[index])\n",
    "#             pct_hra_eligible.append(pct_hra_eligible_list[index])\n",
    "#             pct_asian.append(pct_asian_list[index])\n",
    "#             pct_black.append(pct_black_list[index])\n",
    "#             pct_hispanic.append(pct_hispanic_list[index])\n",
    "#             pct_white.append(pct_white_list[index])\n",
    "#             pct_chronic_absent.append(pct_chronic_absent_list[index])\n",
    "#         elif '2017' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#             borough.append(borough_list[index])\n",
    "#             grade_level.append(grade_level_list[index])\n",
    "#             enrollment.append(enrollment_list[index])\n",
    "#             fam_comm_ties.append(fam_comm_ties_list[index])\n",
    "#             pct_ell.append(pct_ell_list[index])\n",
    "#             pct_disabilites.append(pct_disabilities_list[index])\n",
    "#             pct_self_contained.append(pct_self_contained_list[index])\n",
    "#             economic_need_index.append(economic_need_index_list[index])\n",
    "#             pct_temp_housing.append(pct_temp_housing_list[index])\n",
    "#             pct_hra_eligible.append(pct_hra_eligible_list[index])\n",
    "#             pct_asian.append(pct_asian_list[index])\n",
    "#             pct_black.append(pct_black_list[index])\n",
    "#             pct_hispanic.append(pct_hispanic_list[index])\n",
    "#             pct_white.append(pct_white_list[index])\n",
    "#             pct_chronic_absent.append(pct_chronic_absent_list[index])\n",
    "#         elif '2018' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#             borough.append(borough_list[index])\n",
    "#             grade_level.append(grade_level_list[index])\n",
    "#             enrollment.append(enrollment_list[index])\n",
    "#             fam_comm_ties.append(fam_comm_ties_list[index])\n",
    "#             pct_ell.append(pct_ell_list[index])\n",
    "#             pct_disabilites.append(pct_disabilities_list[index])\n",
    "#             pct_self_contained.append(pct_self_contained_list[index])\n",
    "#             economic_need_index.append(economic_need_index_list[index])\n",
    "#             pct_temp_housing.append(pct_temp_housing_list[index])\n",
    "#             pct_hra_eligible.append(pct_hra_eligible_list[index])\n",
    "#             pct_asian.append(pct_asian_list[index])\n",
    "#             pct_black.append(pct_black_list[index])\n",
    "#             pct_hispanic.append(pct_hispanic_list[index])\n",
    "#             pct_white.append(pct_white_list[index])\n",
    "#             pct_chronic_absent.append(pct_chronic_absent_list[index])\n",
    "#         elif '2019' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#             borough.append(borough_list[index])\n",
    "#             grade_level.append(grade_level_list[index])\n",
    "#             enrollment.append(enrollment_list[index])\n",
    "#             fam_comm_ties.append(fam_comm_ties_list[index])\n",
    "#             pct_ell.append(pct_ell_list[index])\n",
    "#             pct_disabilites.append(pct_disabilities_list[index])\n",
    "#             pct_self_contained.append(pct_self_contained_list[index])\n",
    "#             economic_need_index.append(economic_need_index_list[index])\n",
    "#             pct_temp_housing.append(pct_temp_housing_list[index])\n",
    "#             pct_hra_eligible.append(pct_hra_eligible_list[index])\n",
    "#             pct_asian.append(pct_asian_list[index])\n",
    "#             pct_black.append(pct_black_list[index])\n",
    "#             pct_hispanic.append(pct_hispanic_list[index])\n",
    "#             pct_white.append(pct_white_list[index])\n",
    "#             pct_chronic_absent.append(pct_chronic_absent_list[index])\n",
    "#         elif '2020' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#             borough.append(borough_list[index])\n",
    "#             grade_level.append(grade_level_list[index])\n",
    "#             enrollment.append(enrollment_list[index])\n",
    "#             fam_comm_ties.append(fam_comm_ties_list[index])\n",
    "#             pct_ell.append(pct_ell_list[index])\n",
    "#             pct_disabilities.append(pct_disabilities_list[index])\n",
    "#             pct_self_contained.append(pct_self_contained_list[index])\n",
    "#             economic_need_index.append(economic_need_index_list[index])\n",
    "#             pct_temp_housing.append(pct_temp_housing_list[index])\n",
    "#             pct_hra_eligible.append(pct_hra_eligible_list[index])\n",
    "#             pct_asian.append(pct_asian_list[index])\n",
    "#             pct_black.append(pct_black_list[index])\n",
    "#             pct_hispanic.append(pct_hispanic_list[index])\n",
    "#             pct_white.append(pct_white_list[index])\n",
    "#             pct_chronic_absent.append(pct_chronic_absent_list[index])\n",
    "#         else:\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate containers for comment features\n",
    "# raw_message = []\n",
    "# depth = []\n",
    "# dislikes = []\n",
    "# likes = []\n",
    "# name = []\n",
    "# dbns = []\n",
    "# post_date = []\n",
    "\n",
    "# for dbn in dbn_list:\n",
    "#     # Get website \n",
    "#     driver.get('https://insideschools.org/school/' + dbn)\n",
    "#     # Switch to iframe containing script tag\n",
    "#     driver.switch_to.frame(1)\n",
    "#     # Grab the text\n",
    "#     text = driver.page_source\n",
    "#     # Switch out of iframe\n",
    "#     driver.switch_to.default_content()\n",
    "#     # Parse and process the source with BeautifulSoup module by creating an BS object\n",
    "#     soup = BeautifulSoup(text, 'lxml')\n",
    "#     # Access the soup and find the script element's id\n",
    "#     thread = soup.find(\"script\", {\"id\": \"disqus-threadData\"})\n",
    "#     # Turn the bs4 tag into a string, remove the script tag, and access the json\n",
    "#     site_json = json.loads(str(thread)[48:-9])\n",
    "#     # Navigate and loop json, filtering comments by date, to append comments to comments_list\n",
    "#     for comment in site_json['response']['posts']:\n",
    "#         if '2014' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#         elif '2015' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#         elif '2016' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#         elif '2017' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#         elif '2018' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#         elif '2019' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#         elif '2020' in comment['createdAt']:\n",
    "#             raw_message.append(comment['raw_message'])\n",
    "#             depth.append(comment['depth'])\n",
    "#             dislikes.append(comment['dislikes'])\n",
    "#             likes.append(comment['likes'])\n",
    "#             name.append(comment['author']['name'])\n",
    "#             post_date.append(comment['createdAt'])\n",
    "#             dbns.append(dbn)\n",
    "#         else:\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# Check that all lists are of the same length\n",
    "print(len(dbns))\n",
    "print(len(name))\n",
    "print(len(raw_message))\n",
    "print(len(likes))\n",
    "print(len(dislikes))\n",
    "print(len(depth))\n",
    "print(len(post_date))\n",
    "print(len(borough))\n",
    "print(len(grade_level))\n",
    "print(len(enrollment))\n",
    "print(len(fam_comm_ties))\n",
    "print(len(pct_ell))\n",
    "print(len(pct_disabilities))\n",
    "print(len(pct_self_contained))\n",
    "print(len(economic_need_index))\n",
    "print(len(pct_temp_housing))\n",
    "print(len(pct_hra_eligible))\n",
    "print(len(pct_asian))\n",
    "print(len(pct_black))\n",
    "print(len(pct_hispanic))\n",
    "print(len(pct_white))\n",
    "print(len(pct_chronic_absent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Append data to output_list\n",
    "# output_list.append(dbns)\n",
    "# output_list.append(name)\n",
    "# output_list.append(raw_message)\n",
    "# output_list.append(likes)\n",
    "# output_list.append(dislikes)\n",
    "# output_list.append(depth)\n",
    "# output_list.append(post_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = pd.DataFrame()\n",
    "batch_df['dbn'] = dbns\n",
    "batch_df['username'] = name\n",
    "batch_df['borough'] = borough\n",
    "batch_df['grade_level'] = grade_level\n",
    "batch_df['enrollment'] = enrollment\n",
    "batch_df['comment'] = raw_message\n",
    "batch_df['likes'] = likes\n",
    "batch_df['dislikes'] = dislikes\n",
    "batch_df['replies'] = depth\n",
    "batch_df['post_date'] = post_date\n",
    "batch_df['fam_comm_ties'] = fam_comm_ties\n",
    "batch_df['pct_ell'] = pct_ell\n",
    "batch_df['pct_disabilities'] = pct_disabilities\n",
    "batch_df['pct_self_contained'] = pct_self_contained\n",
    "batch_df['economic_need_index'] = economic_need_index\n",
    "batch_df['pct_temp_housing'] = pct_temp_housing\n",
    "batch_df['pct_hra_eligible'] = pct_hra_eligible\n",
    "batch_df['pct_asian'] = pct_asian\n",
    "batch_df['pct_black'] = pct_black\n",
    "batch_df['pct_hispanic'] = pct_hispanic\n",
    "batch_df['pct_white'] = pct_white\n",
    "batch_df['pct_chronic_absent'] = pct_chronic_absent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dbn</th>\n",
       "      <th>username</th>\n",
       "      <th>borough</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>comment</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>replies</th>\n",
       "      <th>post_date</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_disabilities</th>\n",
       "      <th>pct_self_contained</th>\n",
       "      <th>economic_need_index</th>\n",
       "      <th>pct_temp_housing</th>\n",
       "      <th>pct_hra_eligible</th>\n",
       "      <th>pct_asian</th>\n",
       "      <th>pct_black</th>\n",
       "      <th>pct_hispanic</th>\n",
       "      <th>pct_white</th>\n",
       "      <th>pct_chronic_absent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M015</td>\n",
       "      <td>P.S. 15 Parent</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>161</td>\n",
       "      <td>P.S. 15 is an extraordinary small school that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-11T14:13:41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M015</td>\n",
       "      <td>Houleye Sy</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>161</td>\n",
       "      <td>A Hidden Gem!\\nAmazing community school that f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-30T21:22:41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M015</td>\n",
       "      <td>newslink</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>161</td>\n",
       "      <td>PS 15 is among the schools with the most impro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-31T15:09:35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M015</td>\n",
       "      <td>newslink</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>161</td>\n",
       "      <td>PS 15 second graders won a city-wide ferry nam...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-14T15:47:05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M015</td>\n",
       "      <td>newslink</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>161</td>\n",
       "      <td>NYC Department of Education officials barred a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-14T21:27:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dbn        username    borough grade_level  enrollment  \\\n",
       "0  01M015  P.S. 15 Parent  manhattan  Elementary         161   \n",
       "1  01M015      Houleye Sy  manhattan  Elementary         161   \n",
       "2  01M015        newslink  manhattan  Elementary         161   \n",
       "3  01M015        newslink  manhattan  Elementary         161   \n",
       "4  01M015        newslink  manhattan  Elementary         161   \n",
       "\n",
       "                                             comment  likes  dislikes  \\\n",
       "0  P.S. 15 is an extraordinary small school that ...      0         0   \n",
       "1  A Hidden Gem!\\nAmazing community school that f...      0         0   \n",
       "2  PS 15 is among the schools with the most impro...      0         0   \n",
       "3  PS 15 second graders won a city-wide ferry nam...      0         0   \n",
       "4  NYC Department of Education officials barred a...      0         0   \n",
       "\n",
       "   replies            post_date  ...  pct_disabilities  pct_self_contained  \\\n",
       "0        0  2020-05-11T14:13:41  ...              0.23               0.006   \n",
       "1        0  2020-04-30T21:22:41  ...              0.23               0.006   \n",
       "2        0  2017-08-31T15:09:35  ...              0.23               0.006   \n",
       "3        0  2017-04-14T15:47:05  ...              0.23               0.006   \n",
       "4        0  2016-11-14T21:27:00  ...              0.23               0.006   \n",
       "\n",
       "   economic_need_index  pct_temp_housing  pct_hra_eligible  pct_asian  \\\n",
       "0                0.889             0.398              0.77      0.124   \n",
       "1                0.889             0.398              0.77      0.124   \n",
       "2                0.889             0.398              0.77      0.124   \n",
       "3                0.889             0.398              0.77      0.124   \n",
       "4                0.889             0.398              0.77      0.124   \n",
       "\n",
       "   pct_black  pct_hispanic  pct_white  pct_chronic_absent  \n",
       "0       0.28         0.553      0.037               0.227  \n",
       "1       0.28         0.553      0.037               0.227  \n",
       "2       0.28         0.553      0.037               0.227  \n",
       "3       0.28         0.553      0.037               0.227  \n",
       "4       0.28         0.553      0.037               0.227  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df.loc[(batch_df['dbn'] == '01M019') & (batch_df['replies'] > 0)].iloc[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df.comment.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df.comment.str.len().max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of comments per school\n",
    "batch_df.dbn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with list of data base numbers\n",
    "batch_df = pd.DataFrame(dbn_list, columns=['dbn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add comments of recently scraped batch of comments to comments column \n",
    "batch_df['comments'] = output_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data frame to CSV and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df.to_csv('batch_1000-end_comments.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
